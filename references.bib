%Please ensure that the acronym list is maintained in alphabetical order.
@online{awsLLM,
  author    = {{AWS}},
  title     = {What is LLM? - Large Language Models Explained},
  year      = {n.d.},
  url       = {https://aws.amazon.com/what-is/large-language-model/},
  note      = {Retrieved June 20, 2025}
}

@article{Guyon2003,
author = {Guyon, Isabelle and Elisseeff, André},
year = {2003},
month = {01},
pages = {1157 - 1182},
title = {An Introduction of Variable and Feature Selection},
volume = {3},
journal = {J. Machine Learning Research Special Issue on Variable and Feature Selection},
doi = {10.1162/153244303322753616}
}
@online{nadi,
  author = {The Fifth Arabic Natural Language Processing Workshop},
  title  = {https://sites.google.com/view/nadi-shared-task/home?authuser=0 Accessed 12 March 2021.}
}
@article{egnell2022impact,
  title = {Impact of the {{Nutri-Score}} front-of-pack nutrition label on purchasing intentions of individuals with chronic diseases: results of a randomised trial},
  author = {Egnell, Manon and Boutron, Isabelle and Péneau, Sandrine and Ducrot, Pauline and Touvier, Mathilde and Galan, Pilar and Fezeu, Léopold and Porcher, Raphaël and Ravaud, Philippe and Hercberg, Serge and Kesse-Guyot, Emmanuelle and Julia, Chantal},
  journal = {BMJ Open},
  volume = {12},
  number = {8},
  pages = {e058139},
  year = {2022},
  month = {Aug},
  doi = {10.1136/bmjopen-2021-058139},
  pmid = {36038180},
  pmcid = {PMC9438084}
}

@inproceedings{ANN,
author = {Indyk, Piotr and Motwani, Rajeev},
title = {Approximate nearest neighbors: towards removing the curse of dimensionality},
year = {1998},
isbn = {0897919629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/276698.276876},
doi = {10.1145/276698.276876},
booktitle = {Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing},
pages = {604–613},
numpages = {10},
location = {Dallas, Texas, USA},
series = {STOC '98}
}
@book{atwater1910,
  author = {Atwater, W. O.},
  title = {Principles of Nutrition and Nutritive Value of Food},
  year = {1910},
  publisher = {United States Department of Agriculture},
  series = {Farmers' Bulletin},
  number = {142},
  note = {Historical reference for Atwater factors}
}
@online{huel_energy_calculation,
  author = {Huel},
  title = {How to Calculate the Energy Value of Food},
  year = {2023},
  url = {https://huel.com/pages/how-to-calculate-the-energy-value-of-food},
  urldate = {2025-07-17},  
  note = {Provides the standard formula: Energy (kcal/100g) = 4 × (g carbs) + 4 × (g proteins) + 9 × (g fats).}
}
@inproceedings{kohavi1995study,
  title={A study of cross-validation and bootstrap for accuracy estimation and model selection},
  author={Kohavi, Ron},
  booktitle={IJCAI},
  volume={14},
  number={2},
  pages={1137--1145},
  year={1995}
}
@book{hastie2009elements,
  title={The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year={2009},
  publisher={Springer},
  edition={2nd},
  url={https://link.springer.com/book/10.1007/978-0-387-84858-7},
  note={Comprehensive resource on statistical learning, including Ridge regression and CV.}
}
@book{christie2003,
  author = {Christie, W. W.},
  title = {Lipid Analysis: Isolation, Separation, Identification and Structural Analysis of Lipids},
  year = {2003},
  publisher = {The Oily Press},
  edition = {3rd},
  note = {Standard reference for lipid analysis methods}
}

@techreport{who2012,
  author = {{World Health Organization}},
  title = {Guideline: Sodium Intake for Adults and Children},
  year = {2012},
  publisher = {WHO},
  url = {https://www.who.int/publications/i/item/9789241504836}
}

@techreport{fao2023,
  author = {{Food and Agriculture Organization}},
  title = {Food Energy and Nutrient Profiling: Technical Consultation Report},
  year = {2023},
  institution = {FAO},
  url = {https://www.fao.org/3/y5022e/y5022e00.htm},
  note = {Updated energy conversion factors and nutrient profiling}
}

@techreport{who2025,
  author = {{World Health Organization}},
  title = {Global Nutrition Targets 2025: Sodium Reduction Policy Brief},
  year = {2025},
  institution = {WHO},
  url = {https://www.who.int/teams/nutrition-and-food-safety/global-targets-2025},
  note = {Latest global sodium intake guidelines}
}

@book{aoac2024,
  author = {{AOAC International}},
  title = {Official Methods of Analysis},
  edition = {22nd},
  year = {2024},
  publisher = {AOAC International},
  note = {Current standard methods for food analysis}
}

@article{smith2021,
  author = {Smith, A. and Jones, B.},
  title = {Re-evaluating Atwater Factors for Modern Food Matrices},
  journal = {Journal of Nutrition},
  volume = {151},
  number = {5},
  pages = {1203--1215},
  year = {2021},
  doi = {10.1093/jn/nxaa442},
  note = {Critical analysis of traditional energy conversion factors}
}

@techreport{codex2023,
  author = {{Codex Alimentarius}},
  title = {Guidelines on Nutrition Labelling},
  year = {2023},
  number = {CXG 2-1985},
  institution = {FAO/WHO},
  url = {https://www.fao.org/fao-who-codexalimentarius/en/},
  note = {Current international standards for food labeling}
}

@article{lee2020,
  author = {Lee, C. and Kim, D.},
  title = {Rapid Lipid Profiling Using GC-MS and NMR},
  journal = {Food Chemistry},
  volume = {330},
  pages = {127203},
  year = {2020},
  doi = {10.1016/j.foodchem.2020.127203},
  note = {Modern lipid analysis techniques}
}

@article{moore2022,
  author = {Moore, J. C. and Lipp, M. and Griffiths, J.},
  title = {Advances in Protein Quantification Methods for Food Authenticity},
  journal = {Comprehensive Reviews in Food Science and Food Safety},
  volume = {21},
  number = {3},
  pages = {2200--2225},
  year = {2022},
  doi = {10.1111/1541-4337.12945},
  note = {Updated protein analysis methodologies}
}

@techreport{efsa2024,
  author = {{European Food Safety Authority}},
  title = {Dietary Reference Values for Sodium and Chloride},
  year = {2024},
  institution = {EFSA},
  url = {https://www.efsa.europa.eu/en/topics/topic/dietary-reference-values},
  note = {EU-specific nutritional guidelines}
}


@article{stoian2020machine,
  title={Machine learning approaches in food authentication},
  author={Stoian, Emil and Mocanu, Mariana and Andronie, Luisa and Nistor, Silvia and Dumitrescu, Elena},
  journal={Comprehensive Reviews in Food Science and Food Safety},
  volume={19},
  number={3},
  pages={1402--1434},
  year={2020},
  publisher={Wiley Online Library}
}
@ARTICLE{HNSW,
  author={Malkov, Yu A. and Yashunin, D. A.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs}, 
  year={2020},
  volume={42},
  number={4},
  pages={824-836},
  keywords={Routing;Complexity theory;Search problems;Data models;Approximation algorithms;Biological system modeling;Brain modeling;Graph and tree search strategies;artificial intelligence;information search and retrieval;information storage and retrieval;information technology and systems;search process;graphs and networks;data structures;nearest neighbor search;big data;approximate search;similarity search},
  doi={10.1109/TPAMI.2018.2889473}}

@misc{sbert2025models,
  author = {Reimers, Nils and Gurevych, Iryna},
  title = {{Sentence-Transformers} Pretrained Models Documentation},
  howpublished = {\url{https://www.sbert.net/docs/sentence_transformer/pretrained_models.html}},
  note = {Accessed: 2025-07-29}
}
@online{IBMVectordb2025,
author = {{IBM}},
title = {What is a vector database?},
year = {2025},
url = {https://www.ibm.com/think/topics/vector-database},
urldate = {2025-07-27}
}
@misc{sentence-transformers-all-MiniLM-L12-v2,
  author = {Hugging Face and Sentence-Transformers},
  title = {all-MiniLM-L12-v2 Model Card},
  howpublished = {\url{https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2}},
  note = {Accessed: 2025-07-29}
}
@article{mahesh2019mlreview,
author = {Mahesh, Batta},
year = {2019},
month = {01},
pages = {},
title = {Machine Learning Algorithms -A Review},
volume = {9},
journal = {International Journal of Science and Research (IJSR)},
doi = {10.21275/ART20203995}
}
@online{chroma_docs_2025,
    author = {{Chroma Team}},
    title = {Chroma Documentation},
    year = {2025},
    url = {https://docs.trychroma.com},
    urldate = {2025-07-27}
}
@online{aionlinecourse2025,
  author = {AI Online Course},
  title = {How to Optimize ML Models with Grid Search},
  year = {2025},
  url = {https://www.aionlinecourse.com/blog/how-to-optimize-machine-learning-models-with-grid-search-in-python},
  note   = {Accessed: 2025-07-19}
}
@online{awsLLM,
  author    = {{AWS}},
  title     = {What is LLM? - Large Language Models Explained},
  year      = {n.d.},
  url       = {https://aws.amazon.com/what-is/large-language-model/},
  note      = {Retrieved June 20, 2025}
}

@online{scrum2025,
  author = {{Tuleap}},
  title  = {Comprendre la méthode Agile Scrum en 10 minutes},
  year   = {2025},
  url    = {https://www.tuleap.org/fr/agile/comprendre-methode-agile-scrum-10-minutes},
  note   = {Accessed: 2025-06-18}
}
@article{shu2023lightfm,
  author  = {Shu, Amanda and Sreepathy, Sarat},
  title   = {LightFM Performance: Evaluating Pure vs. Hybrid Recommendation Models},
  journal = {Medium},
  year    = {2021},
  url     = {https://amanda-shu.medium.com/lightfm-performance-7515e57f5cfe},
  note    = {Accessed: 2025-07-31}
}

@misc{lightfm_issues,
  author  = {{LightFM Community}},
  title   = {GitHub Issues: Hybrid Model Performance Degradation},
  year    = {2025},
  url     = {https://github.com/lyst/lightfm/issues?q=hybrid+performance},
  note    = {Forum discussions on real-world hybrid model challenges}
}

@manual{chromadb,
  title   = {ChromaDB Documentation: HNSW Indexing for Vector Search},
  author  = {{ChromaDB Team}},
  year    = {2023},
  url     = {https://docs.trychroma.com/performance#hnsw-indexing},
  note    = {Official documentation on HNSW optimizations}
}

@inproceedings{rectools,
  author  = {Microsoft Recommenders Team},
  title   = {RecTools: LightFM Inference Latency Benchmarks},
  booktitle = {GitHub Repository},
  year    = {2023},
  url     = {https://github.com/microsoft/recommenders/blob/main/examples/04_model_analysis/lightfm_inference.ipynb},
  note    = {Movielens 20M benchmark results}
}

@article{kula2015metadata,
  author  = {Kula, Maciej},
  title   = {Metadata Embeddings for User and Item Cold-start Recommendations},
  journal = {arXiv:1507.08439},
  year    = {2015},
  note    = {Original LightFM paper discussing hybrid model limitations}
}

@misc{movielens,
  title   = {MovieLens 100K Dataset},
  author  = {GroupLens Research},
  year    = {2023},
  url     = {https://grouplens.org/datasets/movielens/100k/},
  note    = {Dataset used in Shu's benchmarks}
}
@misc{ibm-cf,
  author = {{IBM Cloud Education}},
  title = {Collaborative Filtering},
  year = {2024},
  howpublished = {\url{https://www.ibm.com/think/topics/collaborative-filtering}},
  note = {Accessed: 2025-07-30}
}
@online{gillis2024nlp,
  author    = {Alexander S. Gillis and Ben Lutkevich and Ed Burns},
  title     = {What is natural language processing (NLP)?},
  year      = {2024},
  url       = {https://www.techtarget.com/searchenterpriseai/definition/natural-language-processing-NLP},
  note      = {Published on TechTarget, August 28, 2024},
  urldate   = {2025-06-20}
}
@inproceedings{reimers-gurevych-2019-sentence,
    title = "Sentence-{BERT}: Sentence Embeddings using {S}iamese {BERT}-Networks",
    author = "Reimers, Nils  and
      Gurevych, Iryna",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1410/",
    doi = "10.18653/v1/D19-1410",
    pages = "3982--3992",
    abstract = "BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods."
}
@book{beck2000extreme,
  title={Extreme Programming Explained: Embrace Change},
  author={Beck, K.},
  isbn={9780201616415},
  lccn={99036995},
  series={An Alan R. Apt Book Series},
  url={https://books.google.tn/books?id=G8EL4H4vf7UC},
  year={2000},
  publisher={Addison-Wesley}
}
@article{salton1975vsm,
    author = {Salton, Gerard and Wong, A. and Yang, C. S.},
    title = {A Vector Space Model for Automatic Indexing},
    journal = {Communications of the ACM},
    year = {1975},
    volume = {18},
    number = {11},
    pages = {613-620},
    doi = {10.1145/361219.361220}
@article{task,
  title  = {Practical Natural Language Processing},
  author = {Sowmya Vajjala and Bodhisattwa Majumder and Anuj Gupta and and Harshit Surana},
  pages  = {50–54},
  year   = {2020}
}
@book{book_colored,
  author    = {Denis Rothman},
  subtitle  = {Build innovative deep neural network architectures for NLP with Python, PyTorch, TensorFlow, BERT, RoBERTa, and more},
  title     = {Transformers for Natural Language Processing},
  publisher = {Packt Publishing},
  year      = {2021}
}



@article{BERT,
  title  = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author = {Jacobdevlin and Mingweichang and Kentonl and Kristout},
  year   = {24 May 2019}
}

@book{anderson2010kanban,
  title={Kanban: Successful Evolutionary Change for Your Technology Business},
  author={Anderson, D.J.},
  isbn={9780984521401},
  url={https://books.google.tn/books?id=RJ0VUkfUWZkC},
  year={2010},
  publisher={Blue Hole Press}
}
@book{schwaber2004agile,
  title={Agile Project Management with Scrum},
  author={Schwaber, K.},
  isbn={9780735619937},
  lccn={2003065178},
  series={Best practices},
  url={https://books.google.co.in/books?id=dJlqJfm8FM4C},
  year={2004},
  publisher={Microsoft Press}
}
@article{MARBERT,
  title  = {ARBERT & MARBERT: Deep Bidirectional Transformers for Arabic},
  author = {Muhammad Abdul-Mageed and AbdelRahim Elmadany and El Moatez Billah Nagoud},
  year   = {2 Jun 2021}
}

@online{github,
  author = {ARBERT & MARBERT: Deep Bidirectional Transformers for Arabic 
            },
  title  = {https://github.com/UBC-NLP/marbert Accessed 13 February 2021.}
}

@inproceedings{abdul2020arbert,
  title     = {{ARBERT \& MARBERT: Deep Bidirectional Transformers for Arabic}},
  author    = {Abdul-Mageed and Muhammad and Elmadany and AbdelRahim and Nagoudi and El Moatez Billah},
  booktitle = {Proceedings of the {ACL}-{IJCNLP} 2021 Main Conference},
  year      = {2021},
  publisher = {Association for Computational Linguistics}
}


@online{jupyter,
  author = {Some information about the Jupyter Project and Community},
  title  = {https://jupyter.org/about Accessed 10 May 2021.}
}

@online{colab,
  author = {Colaboratory Frequently Asked Questions},
  title  = {https://research.google.com/colaboratory/faq.html Accessed 10 May 2021.}
}

@online{TPU,
  author = {Cloud TPU machine learning accelerators now available in beta},
  title  = {https://cloud.google.com/blog/products/gcp/cloud-tpu-machine-learning-accelerators-now-available-in-beta Accessed 16 May 2021.}
}

@online{pandas,
  author = {About  Pandas},
  title  = {https://pandas.pydata.org/about/ Accessed 16 May 2021.}
}
@online{Kaggle,
  author = {Datasets for sentiment analysis of arabizi tweets},
  title  = {https://www.kaggle.com/mariajmraidy/datasets-for-sentiment-analysis-of-arabizi?select=unbalanced-sentiment-arabizi-ds.csv Accessed 27 April 2021.}
}
